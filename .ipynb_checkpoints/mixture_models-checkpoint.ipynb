{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization - Gaussian Mixture Model & K-mean Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This is a pet project where I trained a mixture of Gaussians (Gaussian Mixture Model) to represent an image and segment it according to the simplified representation. The model is trained with expectation-maximization.\n",
    "\n",
    "**Note:** a highlight of this project is that, due to the huge volume of data manipulcation/calculation, code vectorization is applied using numpy package with multi-layer matrix (k x m x n). It's a good vectoration experiement. :) \n",
    "\n",
    "In details, the project consists of following steps: \n",
    "1. [Warm-up] Implement k-means clustering to segment a color image.\n",
    "2. Construct a Gaussian mixture model to be trained with expectation-maximization.\n",
    "3. Play around with the details of the Gaussian mixture modelâ€™s implementation.\n",
    "4. Implement and test a new metric called the Bayesian information criterion, which guarantees a more robust image segmentation.\n",
    "\n",
    "**Result Preview**: Image segamentation with K-mean Clustering (K = 20):\n",
    "\n",
    "![bird_color](images/bird_color_24.png)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K-means Clustering\n",
    "\n",
    "As a warm-up, k-means clustering is an easy method to do image segmentation. It simply clusters all similar data points together and then replace with the mean value. **Vectorization is need!**\n",
    "\n",
    "### Steps: \n",
    "1. K-means Clustering - 2D dataset & its visualization (interative charts provided)\n",
    "2. K-means Clustering - Image Segmentation & its visualization\n",
    "\n",
    "`get_initial_means()`: Calculate initial cluster means by selecting k number of points from the data (without replacement)\n",
    "\n",
    "`k_means_step()`: A single update/step of the K-means algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '__main__.helper_functions'; '__main__' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-76b42138f575>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# IF YOU ACCIDENTALL RUN IT, IT'S OK, YOU CAN IGNORE THE ERRORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhelper_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named '__main__.helper_functions'; '__main__' is not a package"
     ]
    }
   ],
   "source": [
    "# DON'T RUN THIS CELL IT WILL THROW AN ERROR\n",
    "# IF YOU ACCIDENTALL RUN IT, IT'S OK, YOU CAN IGNORE THE ERRORS\n",
    "import numpy as np\n",
    "from .helper_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Load all necessary modules\n",
    "from IPython.html.widgets import *\n",
    "import mixture_tests as tests\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import time as time\n",
    "from helper_functions import *\n",
    "\n",
    "def get_initial_means(array, k):\n",
    "    \"\"\"\n",
    "    Select k random points from the input array (without replacement) to use as initial cluster means\n",
    "\n",
    "    params:\n",
    "    array (np.ndarray): datapoints x features\n",
    "    k (int): number of random points\n",
    "\n",
    "    returns:\n",
    "    initial_means (np.ndarray)\n",
    "    \"\"\"\n",
    "\n",
    "    idx_row = np.arange(array.shape[0])\n",
    "    np.random.shuffle(idx_row)\n",
    "    \n",
    "    return array[idx_row[:k], :]\n",
    "\n",
    "\n",
    "def k_means_step(X, k, means):\n",
    "    \"\"\"\n",
    "    A single update/step of the K-means algorithm. Based on input X and current mean estimate\n",
    "    , calculate new means & predict clusters for each of the pixel\n",
    "    \n",
    "    params:\n",
    "    X (numpy.ndarray): pixels x features (flattened)\n",
    "    k (int)\n",
    "    means (numpy.ndarray): k x features\n",
    "\n",
    "    returns:\n",
    "    new_means (numpy.ndarray): k x features\n",
    "    clusters (numpy.ndarray):  m (vector)\n",
    "    \"\"\"\n",
    "\n",
    "    # Calc the distance of all data points to each mean\n",
    "    dist_all = [np.sqrt(np.sum(np.square(X - mean_i), axis=1)) for mean_i in means]\n",
    "                        \n",
    "    # Calc the argmin of all distances for each data point\n",
    "    clusters = np.argmin(np.array(dist_all), axis=0)\n",
    "    \n",
    "    # Calc new means\n",
    "    new_means = np.array([np.mean(X[clusters == uniq], axis=0) for uniq in np.unique(clusters)])\n",
    "    \n",
    "    return new_means, clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. K-means Clustering - 2D dataset (warm-up!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def K_means_2D_dataset(dataset_index, K):\n",
    "    \"\"\"\n",
    "    Load dataset from the /data folder and keep the training trajectory for later illustration purpose\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the dataset from data folder\n",
    "    X = np.loadtxt(\"data/%d_dataset_X.csv\" % dataset_index, delimiter=\",\")\n",
    "    print(\"The dataset is of a size:\", X.shape)\n",
    "\n",
    "    # Load the labels\n",
    "    # Clustering is unsupervised method, where no labels are provided\n",
    "    # However, load them for illustration purposes.\n",
    "    y = np.int16(np.loadtxt(\"data/%d_dataset_y.csv\" % dataset_index, delimiter=\",\"))\n",
    "\n",
    "    # Runs for n_iterations before terminating\n",
    "    n_iterations = 10\n",
    "    m,n = X.shape\n",
    "    means = get_initial_means(X,K)\n",
    "    clusters = np.zeros([n])\n",
    "    \n",
    "    # Keep track of how clusters and means changed, for visualization purposes\n",
    "    means_history = [means]\n",
    "    clusters_history = [clusters] \n",
    "    for iteration_i in range(n_iterations):\n",
    "        means, clusters = k_means_step(X, K, means)\n",
    "        clusters_history.append(clusters)\n",
    "\n",
    "    return X, y, means_history, clusters_history\n",
    "\n",
    "\n",
    "# Use an interactive cell to see the progress of training the K-means algorithm\n",
    "def get_cluster(i):\n",
    "    # Get the clusters from K-means' i-th iteration\n",
    "    clusters = clusters_history[i] \n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(None, figsize=(15,6)) \n",
    "    plt.suptitle('Drag the slider to see the algorthm training progress')\n",
    "    ax1=plt.subplot(1, 2, 1)\n",
    "    ax1.set_title('K-means clsuters - step %d' % i)\n",
    "    \n",
    "    for k in range(K):\n",
    "        plt.plot(X[clusters==k,0], X[clusters==k,1], '.') # \n",
    "\n",
    "    # The truth clusters\n",
    "    ax2=plt.subplot(1, 2, 2)\n",
    "    ax2.set_title('The truth clusters')\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0],X[y==i,1],'.')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is of a size: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b313ed0cb194cb4baa51a9ec4282faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Visualization of K-means Clustering - 2D dataset #####\n",
    "# Select dataset and set K-param for K-mean clustering\n",
    "dataset_index = 1 \n",
    "K = 3\n",
    "\n",
    "# Get the data\n",
    "X, y, means_history, clusters_history = K_means_2D_dataset(dataset_index, K)\n",
    "\n",
    "# Interactive plot\n",
    "interactive(get_cluster, i=(1,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-means Clustering - Image Segmentation \n",
    "2D data clustering is just a warm-up! Now it's time play with K-means for real image segementation!\n",
    "\n",
    "`k_means_segment()`: Separate the provided RGB values into k clusters using the k-means algorithm, then return an updated version of the image with the original values replaced with the corresponding cluster center values.\n",
    "\n",
    "Convergence test: Whether the assigned clusters stop changing (this convergence test could be slow...). Initial cluster means are provided if empty.\n",
    "\n",
    "For visualization purpose, color image data: `bird_color_24.png` is used. It's a multidimensional data with **rows x columns x color_channels**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def k_means_segment(image_values, k=3, initial_means=None):\n",
    "    \"\"\"\n",
    "    Separate the provided RGB values into k separate clusters using the k-means algorithm,\n",
    "    then return an updated version of the image with the original values replaced with\n",
    "    the corresponding cluster values.\n",
    "\n",
    "    params:\n",
    "    image_values (numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]]): rows x columns x color_channels\n",
    "    k = int\n",
    "    initial_means (numpy.ndarray[numpy.ndarray[float]] or None)\n",
    "\n",
    "    returns:\n",
    "    updated_image_values (numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]])\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten the image_value - reshape\n",
    "    height, width, depth = image_values.shape\n",
    "    image_values = image_values.reshape(height * width, depth)\n",
    "    \n",
    "    if initial_means is None:\n",
    "        means = get_initial_means(image_values, k)\n",
    "    else:\n",
    "        means = initial_means\n",
    "    \n",
    "    diff_cls = 100\n",
    "    clusters = np.zeros(image_values.shape[0])\n",
    "    \n",
    "    # Convergence test - no diff in clustering \n",
    "    while diff_cls != 0: \n",
    "        clusters_prev = clusters.copy()   # copy is needed!\n",
    "        means, clusters = k_means_step(image_values, k, means)\n",
    "        diff_cls = np.sum(clusters_prev - clusters)\n",
    "    \n",
    "    # Another convergence test - iteration depth\n",
    "#     itr = 0\n",
    "#     while itr <= iter_depth:\n",
    "#         means, clusters = k_means_step(image_values, k, means)\n",
    "#         itr += 1\n",
    "        \n",
    "    # Return updated image - use mean to represent each cluster\n",
    "    image_values_cp = image_values.copy()\n",
    "    for uniq in np.unique(clusters):\n",
    "        image_values_cp[clusters==uniq] = means[uniq]\n",
    "    \n",
    "    image_values_cp = image_values_cp.reshape(height, width, depth)\n",
    "    \n",
    "    return image_values_cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGVCAYAAADDk5p6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP0hMw6gVArVVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-means Clustering took 5.46982 seconds to converge.\n"
     ]
    }
   ],
   "source": [
    "##### Visualization of K-means Clustering - Image Segmentation #####\n",
    "# Number of clusters\n",
    "K=15\n",
    "\n",
    "tic = time.time()\n",
    "image_values = image_to_matrix('images/bird_color_24.png')\n",
    "new_image = k_means_segment(image_values, k=K)\n",
    "toc = time.time()\n",
    "\n",
    "plt.figure(None,figsize=(9,12))\n",
    "plt.imshow(new_image)\n",
    "plt.show()\n",
    "\n",
    "# time it...\n",
    "print('K-means Clustering - Image Segmentation took %.5f seconds to converge.' % (toc-tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implementing a Multivariate Gaussian Mixture Model (40 pts)\n",
    "\n",
    "Next, we will step beyond clustering and implement a complete Gaussian mixture model.\n",
    "\n",
    "But, before you dive into the code, you are highly encouraged to go over `read/gaussians.pdf` file before you start, to familiarize yourself with multivariate case of the Gaussian distribution.\n",
    "\n",
    "In addition to that, there is a great ~17 minute where Alexander Ihler goes over nuts and bolds of the multivariate EM algorithm details on Youtube:\n",
    "https://www.youtube.com/watch?v=qMTuMa86NzU\n",
    "\n",
    "Another resource you can refer to is the `read/em.pdf` document attached, which is a chapter from Pattern Recognition and Machine Learning book by Christopher M. Bishop.\n",
    "\n",
    "- - - \n",
    "\n",
    "Now it's time, to complete the implementation of the functions below what will later assemble into a Multivariate Gaussian Expectation Maximization algorithm:\n",
    "\n",
    "1. Calculate the probability of a given data point (e.g. rgb value of a pixel) of belonging to a specific Gaussian component. (5 points)\n",
    "\n",
    "2. Use expectation-maximization (EM) to train the model to represent the image as a mixture of Gaussians. (20 points)\n",
    "\n",
    "To initialize EM, set each component's mean to the means value of randomly chosen pixels (same as for K-means) and calculate covariances based on the selected means, and set the mixing coefficients to a uniform distribution. \n",
    "\n",
    "We've set the convergence condition for you in `default_convergence()` (see `helper_functions.py` file): if the new likelihood is within 10% of the previous likelihood for 10 consecutive iterations, the model has converged.\n",
    "\n",
    "**Note:** there are packages that can run EM automagically, but you have to implement your own version of EM without using these extra packages. **It also means that you are not allowed to look into any implementations of the algorithms, e.g scikit-learn and many others. NumPy is your only tool here.** \n",
    "\n",
    "3. Calculate the log likelihood of the trained model. (5 points)\n",
    "4. Segment the image according to the trained model. (5 points)\n",
    "5. Determine the best segmentation by iterating over model training and scoring, since EM isn't guaranteed to converge to the global maximum. (5 points)\n",
    "\n",
    "It'd be helpful to implement the above functions in the following order - \n",
    "1. initialize_parameters\n",
    "2. prob\n",
    "3. E_step\n",
    "4. M_step\n",
    "5. likelihood \n",
    "6. train_model\n",
    "7. cluster\n",
    "8. segment\n",
    "9. best_segment\n",
    "\n",
    "We've provided comments in `mixture_models.py` to help you all along. We have also provided the necessary tests for this part in `mixture_tests.py`. Please make sure to use these tests before submitting to Bonnie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: You may lose all marks for this part if your code runs for too long.\n",
    "\n",
    "### You will need to vectorize your code in this part. Specifically, the method E_step() and M_step() which make up the train_model(), perform operations using numpy arrays. These are time-sensitive functions and will be called over and over as you proceed with this assignment.\n",
    "\n",
    "For the synthetic data test which we provide to check if your training is working, the set is too small and it won't make a difference. But with the actual image that we use ahead, for-loops won't do good. Vectorized code would take under 30 seconds to converge which would typically involve about 15-20 iterations with the convergence function we have here. Inefficient code that uses loops or iterates over each pixel value sequentially, will take hours to run. You don't want to do that.\n",
    "\n",
    "- - -\n",
    "\n",
    "Same as in K-means you will be working with the data of size (m x n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def initialize_parameters(X, k):\n",
    "    \"\"\"\n",
    "    Return initial values for training of the GMM\n",
    "    Set component mean to a random\n",
    "    pixel's value (without replacement),\n",
    "    based on the mean calculate covariance matrices,\n",
    "    and set each component mixing coefficient (PIs)\n",
    "    to a uniform values\n",
    "    (e.g. 4 components -> [0.25,0.25,0.25,0.25]).\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k x 1 \n",
    "    \"\"\"\n",
    "    \n",
    "    row, col = X.shape\n",
    "    \n",
    "    # Select k random pixels as initial means \n",
    "    # shuffle the idx instead of X itself will save a copy of X!\n",
    "    idx = np.arange(row)\n",
    "    np.random.shuffle(idx)\n",
    "    MU = X[idx[:k], :]\n",
    "    \n",
    "    # Calc cov matrix based on random selected means\n",
    "    SIGMA = np.zeros((k, col, col))\n",
    "    for k_i in range(k):\n",
    "        SIGMA[k_i, :, :] = (1/row) * np.matmul((X - MU[k_i]).T, (X - MU[k_i]))\n",
    "    \n",
    "    # Calc PI\n",
    "    PI = np.repeat(1/k, k)\n",
    "    \n",
    "    return MU, SIGMA, PI\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_initialization(initialize_parameters)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def prob(x, mu, sigma):\n",
    "    \"\"\"Calculate the probability of a single\n",
    "    data point x under component with\n",
    "    the given mean and covariance.\n",
    "    # NOTE: there is nothing to vectorize here yet,\n",
    "    # it's a simple check to make sure you got the\n",
    "    # multivariate normal distribution formula right\n",
    "    # which is given by N(x;MU,SIGMA) above\n",
    "\n",
    "    params:\n",
    "    x = numpy.ndarray[float]\n",
    "    mu = numpy.ndarray[float]\n",
    "    sigma = numpy.ndarray[numpy.ndarray[float]]\n",
    "\n",
    "    returns:\n",
    "    probability = float\n",
    "    \"\"\"\n",
    "    \n",
    "    # Modifty this function to handle vector input of x!\n",
    "    # Need to expand dim if input is a single 1*n\n",
    "    if len(x.shape) == 1:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    row, col = x.shape\n",
    "    det_cov = np.linalg.det(sigma)\n",
    "    norm_coef = 1 / (np.sqrt(np.power(2 * np.pi, col) * det_cov))\n",
    "    \n",
    "    x_mu = x - mu\n",
    "    inv_cov = np.linalg.inv(sigma)\n",
    "    norm_main = np.sum(np.multiply(np.dot(x_mu, inv_cov), x_mu), axis=1) # this is the vectorization (not optimal...)\n",
    "    norm_exp = np.exp((-0.5) * norm_main)\n",
    "    \n",
    "    norm_pdf = norm_coef * norm_exp\n",
    "    \n",
    "    # Output has to be float if input x is 1*n, otherwise, output is vector m*n\n",
    "    if row == 1:\n",
    "        return norm_pdf[0]\n",
    "    else:\n",
    "        return norm_pdf\n",
    "    \n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_prob(prob)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def E_step(X,MU,SIGMA,PI,k):\n",
    "    \"\"\"\n",
    "    E-step - Expectation \n",
    "    Calculate responsibility for each\n",
    "    of the data points, for the given \n",
    "    MU, SIGMA and PI.\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k x 1\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "    \n",
    "    row, col = X.shape\n",
    "    ri = np.zeros((k, row))\n",
    "    \n",
    "    # Calc Norm pdf of each datum for each cluster k\n",
    "    for ki in range(k):\n",
    "        ri[ki,:] = prob(X, MU[ki], SIGMA[ki])\n",
    "    \n",
    "    # Normalize ri using given PI\n",
    "    PI = np.expand_dims(PI, axis=1)     # need to expand PI to k * 1 !\n",
    "    ri = np.multiply(ri, PI)            # ri: k*m\n",
    "    ri_sum = np.sum(ri, axis=0)         \n",
    "    ri_sum = np.expand_dims(ri_sum, axis=0)  # must expand sum to 1*m to do np.divide later\n",
    "    ri = np.divide(ri, ri_sum)\n",
    "    \n",
    "    return ri\n",
    "    \n",
    "\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_e_step(E_step)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def M_step(X, r, k):\n",
    "    \"\"\"\n",
    "    M-step - Maximization\n",
    "    Calculate new MU, SIGMA and PI matrices\n",
    "    based on the given responsibilities.\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k x 1\n",
    "    \"\"\"\n",
    "\n",
    "    row, col = X.shape\n",
    "    \n",
    "    # Cacl total resp for each cluster k (k*1)\n",
    "    tot_r = np.sum(r, axis=1)\n",
    "    tot_r = np.expand_dims(tot_r, axis=1)    # need to expand dim on column (k,) --> (k,1)\n",
    "\n",
    "    \n",
    "    # Update MU - k*n\n",
    "    X_rwt = np.dot(r, X)   # k*n\n",
    "    new_MU = np.divide(X_rwt, tot_r)\n",
    "    \n",
    "    \n",
    "    # [Vectorization method]Update SIGMA use new_MU\n",
    "    # First reshape matrices to fit the vectorization\n",
    "    new_MU = np.expand_dims(new_MU, axis=1)         # (k*n) --> (k*1*n)\n",
    "    X_tmp = np.tile(X, (k,1)).reshape(k, row, col)  # (m*n) --> (k*m*n)   * don't modify X!\n",
    "    r = np.expand_dims(r, axis=2)                   # (k*1) --> (k*1*1)\n",
    "    tot_r = tot_r.reshape(k, 1, 1)                  # (k*1) --> (k*1*1)\n",
    "    \n",
    "    # Let's show the middle steps, but commented for faster speed (should use X_tmp below...)\n",
    "    # X1 = X - new_MU\n",
    "    # X2 = np.multiply(X1, r)     # element-wise multiply on each layer k: r * (X - new_MU) is done\n",
    "    # X3 = np.transpose(X2, axes=(0,2,1))   # transpose centain axes! (k*m*n) --> (k*n*m)\n",
    "    # X4 = np.matmul(X3, X1)      # must use np.matmul(), np.dot() won't work. (k*n*m) * (k*m*n) --> (k*n*n)\n",
    "    # new_SIGMA = (1/tot_r) * X4  # assign weight on each layer k\n",
    "    \n",
    "    new_SIGMA = (1/tot_r) * \\\n",
    "                np.matmul(np.transpose(np.multiply(r, (X_tmp - new_MU)), axes=(0,2,1)),\n",
    "                          (X_tmp - new_MU))\n",
    "    \n",
    "    # [No vectorization method]Update SIGMA use new_MU\n",
    "    # new_SIGMA = np.zeros((k, col, col))\n",
    "    # for ki in range(k):\n",
    "    #     r_ki = np.expand_dims(r[ki], axis=1)\n",
    "\n",
    "    #     # Update the data X using the r\n",
    "    #     Xtmp = X.copy()\n",
    "    #     Xtmp = Xtmp - new_MU[ki]\n",
    "\n",
    "    #     # Update the k-th Cov\n",
    "    #     new_SIGMA[ki, :, :] = np.dot(np.multiply(Xtmp, r_ki).T, Xtmp) * (1/tot_r[ki])\n",
    "        \n",
    "        \n",
    "    # Update PI\n",
    "    new_PI = tot_r * (1/row)\n",
    "    \n",
    "    \n",
    "    # Reshape back for output\n",
    "    new_MU = new_MU.reshape(k, col)\n",
    "    new_PI = new_PI.reshape(k,)    # need to reshape back (k,1,1) --> (k,)    \n",
    "    \n",
    "    return new_MU, new_SIGMA, new_PI\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_m_step(M_step)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def likelihood(X, PI, MU, SIGMA, k):\n",
    "    \"\"\"Calculate a log likelihood to the \n",
    "    trained model based on the following\n",
    "    formula for posterior probability:\n",
    "    log10(Pr(X | mixing, mean, stdev)) = sum((n=1 to N), log10(sum((k=1 to K),\n",
    "                                      mixing_k * N(x_n | mean_k,stdev_k))))\n",
    "\n",
    "    Make sure you are using log base 10, instead of log base 2.\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k x 1\n",
    "    k = int\n",
    "\n",
    "    returns:\n",
    "    log_likelihood = int\n",
    "    \"\"\"\n",
    "    \n",
    "    row, col = X.shape\n",
    "    likelihood = np.zeros((k, row))\n",
    "    for ki in range(k):\n",
    "        likelihood[ki, :] = PI[ki] * prob(X, MU[ki], SIGMA[ki])\n",
    "        \n",
    "    # Take log of the sum(likelihood)\n",
    "    # middle step : \n",
    "    # np.sum(likelihood, axis=0))   # (1*m)\n",
    "    log_likelihood = np.sum(np.log10(np.sum(likelihood, axis=0)))\n",
    "    \n",
    "    return log_likelihood\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_likelihood(likelihood)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, k, convergence_function, initial_values = None):\n",
    "    \"\"\"\n",
    "    Train the mixture model using the \n",
    "    expectation-maximization algorithm. \n",
    "    Which is an interative execution of\n",
    "    the E and M steps from above.\n",
    "    If the initial_values aer None, initialize them.\n",
    "    Else it's a tuple of the format (MU, SIGMA, PI).\n",
    "    Convergence is reached when convergence_function\n",
    "    returns terminate as True,\n",
    "    see default convergence_function example \n",
    "    in `helper_functions.py`\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    convergence_function = func\n",
    "    initial_values = None or (MU, SIGMA, PI)\n",
    "\n",
    "    params:\n",
    "    returns:\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k x 1\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "\n",
    "    if initial_values is None:\n",
    "        initial_values = initialize_parameters(X, k)\n",
    "    \n",
    "    MU, SIGMA, PI = initial_values\n",
    "    loglike  = 0\n",
    "    conv_ctr = 0\n",
    "    tf_conv  = False\n",
    "    \n",
    "    while (tf_conv==False):\n",
    "        #print('Converge counter: ', conv_ctr)\n",
    "        loglike_pre = loglike\n",
    "        r = E_step(X, MU, SIGMA, PI, k)\n",
    "        MU, SIGMA, PI = M_step(X, r, k)\n",
    "        loglike = likelihood(X, PI, MU, SIGMA, k)\n",
    "        \n",
    "        conv_ctr, tf_conv = convergence_function(loglike_pre, loglike, conv_ctr)\n",
    "        \n",
    "    return MU, SIGMA, PI, r\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_train(train_model, likelihood)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def cluster(r):\n",
    "    \"\"\"\n",
    "    Based on a given responsibilities matrix\n",
    "    return an array of clusters.\n",
    "    Assign each datapoint to a cluster based,\n",
    "    on component with a max-likelihood \n",
    "    (maximum responsibility value).\n",
    "    \n",
    "    params:\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m - responsibility matrix\n",
    "    \n",
    "    return:\n",
    "    clusters = numpy.ndarray[int] - m x 1 \n",
    "    \"\"\"\n",
    "\n",
    "    return np.argmax(r, axis=0)\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_cluster(cluster)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def segment(X, MU, k, r):\n",
    "    \"\"\"\n",
    "    Segment the X matrix into the pre-specified\n",
    "    number of components. Returns the matrix with \n",
    "    the each data point replace with its max-likelihood\n",
    "    component mean. E.g in case of image returns \n",
    "    the original matrix with the each pixel's \n",
    "    intensity replaced with its max-likelihood\n",
    "    component mean. (the shape is still mxn,\n",
    "    not original image size)\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    k = int\n",
    "    r = numpy.ndarray[numpy.ndarray[float]] - k x m - responsibility matrix\n",
    "\n",
    "    returns:\n",
    "    new_X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    \"\"\"\n",
    "\n",
    "    clstr = cluster(r)    # m*1\n",
    "    new_X = X.copy()\n",
    "    for ki in range(k):\n",
    "        new_X[clstr==ki,:] = MU[ki]\n",
    "    \n",
    "    return new_X\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_segment(train_model, segment)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def best_segment(X,k,iters):\n",
    "    \"\"\"Determine the best segmentation\n",
    "    of the image by repeatedly\n",
    "    training the model and\n",
    "    calculating its likelihood.\n",
    "    Return the segment with the\n",
    "    highest likelihood.\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    iters = int\n",
    "\n",
    "    returns:\n",
    "    likelihood = float\n",
    "    segment = numpy.ndarray[numpy.ndarray[float]]\n",
    "    \"\"\"\n",
    "    \n",
    "    likelihood_max = -np.inf\n",
    "    segment_bst = X.copy()\n",
    "    i = 0\n",
    "    \n",
    "    while i<=iters:\n",
    "        # Keep training the model (random initialize)\n",
    "        MU, SIGMA, PI, r = train_model(X, k, \n",
    "                                       convergence_function = default_convergence, \n",
    "                                       initial_values = None)\n",
    "        \n",
    "        # Segment the X using the training results\n",
    "        Xnew = segment(X, MU, k, r)\n",
    "        likelihood_tmp = likelihood(Xnew, PI, MU, SIGMA, k)\n",
    "        \n",
    "        # Update the best segment\n",
    "        if likelihood_tmp > likelihood_max:\n",
    "            likelihood_max = likelihood_tmp\n",
    "            # segment_bst = Xnew.copy()\n",
    "            segment_bst = Xnew  # let's see what if we don't give a copy\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    return likelihood_max, segment_bst\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_best_segment(best_segment)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GMM - Visualizing the results\n",
    "\n",
    "Now that you are done with the EM implementation lets try to visualize what's happening if you repeat these steps multiple times.\n",
    "\n",
    "**You don't need to be implementing anything in the next 2 cells, but you are highly encouraged to play with parameters and datasets, to get a visual sense of what is happening at every step.\n",
    "\n",
    "\n",
    "Feel free to explore and improve the function below, it will be used for visualizing K-means progress\n",
    "but it's not required and WON'T effect your grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GMM_2D_dataset(dataset_index, K):\n",
    "    # Load the dataset from data folder\n",
    "    X = np.loadtxt(\"data/%d_dataset_X.csv\" % dataset_index, delimiter=\",\")\n",
    "    print(\"There are %d datapoints in the current dataset, each of a size %d\" % X.shape)\n",
    "    # Load the labels\n",
    "    # Clustering is unsupervised method, where no labels are provided\n",
    "    # However, since we generated the data outselves we know the labels,\n",
    "    # and load them for illustration purposes.\n",
    "    y = np.int16(np.loadtxt(\"data/%d_dataset_y.csv\" % dataset_index, delimiter=\",\"))\n",
    "    # Feel free to edit the termination condition for the EM algorithm\n",
    "    # Currently is just runs for n_iterations, before terminating\n",
    "    \n",
    "    MU, SIGMA, PI = initialize_parameters(X, K)\n",
    "    \n",
    "    clusters_history = []\n",
    "    for _ in range(200):\n",
    "        r = E_step(X,MU,SIGMA,PI,K)\n",
    "        new_MU, new_SIGMA, new_PI = M_step(X, r, K)\n",
    "        PI, MU, SIGMA = new_PI, new_MU, new_SIGMA\n",
    "        clusters = cluster(r)\n",
    "        clusters_history.append(clusters)\n",
    "\n",
    "    return X, y, clusters_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 datapoints in the current dataset, each of a size 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568af254de804618a80c2386f2db6fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=99, description='i', max=199), Output()), _dom_classes=('widget-interactâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRY DIFFERENT PARAMETERS\n",
    "dataset_index = 4 # for different dataset change it to number from [0,5]\n",
    "K = 3 # Number of clusters - play with this number\n",
    "\n",
    "X, y, clusters_history = GMM_2D_dataset(dataset_index, K)\n",
    "\n",
    "# This is an interactive cell to see the progress of training your GMM algorithm.\n",
    "# Feel free to improve the visualization code and share it with your classmates on Piazza.\n",
    "def get_cluster(i):\n",
    "    clusters = clusters_history[i] # Get the clusters from K-means' i-th iteration\n",
    "    plt.figure(None, figsize=(15,6)) # Set the plot size\n",
    "    plt.suptitle('Drag the slider to see the algorthm training progress')\n",
    "    ax1=plt.subplot(1, 2, 1)\n",
    "    ax1.set_title('K-means clsuters - step %d' % i)\n",
    "    for k in range(K):\n",
    "        plt.plot(X[clusters==k,0], X[clusters==k,1], '.') # \n",
    "        # Try to plot the centers of the clusters \n",
    "        # You can access them by calling means_history[i]\n",
    "        # How could you plot the area that belong to that cluster?\n",
    "\n",
    "    # Just to get a flavour of how the data looks like\n",
    "    ax2=plt.subplot(1, 2, 2)\n",
    "    ax2.set_title('Ground truth clusters')\n",
    "    for i in np.unique(y):\n",
    "        ax2.plot(X[y==i,0],X[y==i,1],'.')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "interactive(get_cluster, i=(0,len(clusters_history)-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's visualize the image compression results of GMM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_segment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3f642f06cf45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# start = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_seg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_segment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;31m# end = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# print('Time collapes: ', (end-start))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_segment' is not defined"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "image_file = 'images/bird_color_24.png' # Image path\n",
    "original_image_matrix = image_to_matrix(image_file) # Save original image\n",
    "image_matrix = original_image_matrix.reshape(-1,3) # collapse the dimension\n",
    "K = 5 # K\n",
    "\n",
    "# start = time.time()\n",
    "_, best_seg = best_segment(image_matrix, K, iters = 10)\n",
    "# end = time.time()\n",
    "# print('Time collapes: ', (end-start))\n",
    "\n",
    "new_image = best_seg.reshape(*original_image_matrix.shape) # reshape collapsed matrix to original size\n",
    "# Show the image\n",
    "plt.figure(None,figsize=(9,12))\n",
    "plt.imshow(new_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model Experimentation (20 pts)\n",
    "\n",
    "We'll now experiment with a few methods for improving GMM performance.\n",
    "\n",
    "## Part 3a: Improved Initialization \n",
    "\n",
    "12.5 points\n",
    "\n",
    "To run EM in our baseline Gaussian mixture model, we use random initialization to determine the initial values for our component means. We can do better than this!\n",
    "\n",
    "Fill in `improved_initialization()` with an improvement in component initialization. Please don't use any external packages for anything other than basic calculations. Note that your improvement might significantly slow down runtime, although we don't expect you to spend more than 10 minutes on initialization.\n",
    "\n",
    "Hint: you'll probably want an unsupervised learning method to initialize your component means. Clustering is one useful example of unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved_likelihood:  65666.62963381904\n",
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def improved_initialization(X,k):\n",
    "    \"\"\"\n",
    "    Initialize the training\n",
    "    process by setting each\n",
    "    component mean using some algorithm that\n",
    "    you think might give better means to start with,\n",
    "    based on the mean calculate covariance matrices,\n",
    "    and set each component mixing coefficient (PIs)\n",
    "    to a uniform values\n",
    "    (e.g. 4 components -> [0.25,0.25,0.25,0.25]).\n",
    "    \n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    \n",
    "    returns:\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k x 1 \n",
    "    \"\"\"\n",
    "\n",
    "    # First pick random means to start with\n",
    "    row, col = X.shape\n",
    "    idx = np.arange(row)\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    MU = X[idx[:k], :]\n",
    "    PI = np.repeat(1/k, k)\n",
    "    \n",
    "    # Run K-means itr times and calc loglikelihood each time\n",
    "    likelihood_max = -np.inf\n",
    "    MU_best = MU.copy()\n",
    "    SIGMA_best = np.zeros((k, col, col))\n",
    "    \n",
    "    i = 0\n",
    "    itr = 20\n",
    "    while i <= itr:\n",
    "        # Update means\n",
    "        MU, _ = k_means_step(X, k, MU)\n",
    "        \n",
    "        # Calc sigma\n",
    "        MU = np.expand_dims(MU, axis=1)    # (k*n) --> (k*1*n)\n",
    "        SIGMA = (1/row) * np.matmul(np.transpose((np.tile(X, (k,1)).reshape(k, row, col) - MU), axes=(0,2,1)), \n",
    "                                    (np.tile(X, (k,1)).reshape(k, row, col) - MU))     # (m*n) --> (k*m*n)\n",
    "        likelihood_tmp = likelihood(X, PI, MU, SIGMA, k)\n",
    "        \n",
    "        # Pick the one with highest likelihood\n",
    "        if likelihood_tmp > likelihood_max:\n",
    "            likelihood_max = likelihood_tmp\n",
    "            MU_best = MU.reshape(k, col).copy()\n",
    "            SIGMA_best = SIGMA.copy()\n",
    "        \n",
    "        i += 1\n",
    "    \n",
    "    \n",
    "    return MU_best, SIGMA_best, PI\n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_gmm_improvement(improved_initialization, initialize_parameters, train_model, likelihood)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3b: Convergence Condition\n",
    "\n",
    "7.5 points\n",
    "\n",
    "You might be skeptical of the convergence criterion we've provided in `default_convergence()`. To test out another convergence condition, implement `new_convergence_condition()` to return true if all the new model parameters (means, variances, and mixing coefficients) are within 10% of the previous variables for 10 consecutive iterations. This will mean re-implementing `train_model()`, which you will also do in `train_model_improved()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def new_convergence_function(previous_variables, new_variables, conv_ctr,\n",
    "                             conv_ctr_cap=10):\n",
    "    \"\"\"\n",
    "    Convergence function\n",
    "    based on parameters:\n",
    "    when all variables vary by\n",
    "    less than 10% from the previous\n",
    "    iteration's variables, increase\n",
    "    the convergence counter.\n",
    "\n",
    "    params:\n",
    "\n",
    "    previous_variables = [numpy.ndarray[float]]\n",
    "                         containing [means, variances, mixing_coefficients]\n",
    "    new_variables = [numpy.ndarray[float]]\n",
    "                    containing [means, variances, mixing_coefficients]\n",
    "    conv_ctr = int\n",
    "    conv_ctr_cap = int\n",
    "\n",
    "    return:\n",
    "    conv_ctr = int\n",
    "    converged = boolean\n",
    "    \"\"\"\n",
    "\n",
    "    # Calc each param %age change use element-wise calculation\n",
    "    tf_cov_all = []\n",
    "    for para_i in range(len(previous_variables)):\n",
    "        chg_tmp = abs(np.divide(np.subtract(new_variables[para_i], previous_variables[para_i]), \n",
    "                                previous_variables[para_i]))\n",
    "        tf_cov_parai = np.max(chg_tmp) <= 0.05\n",
    "        tf_cov_all.append(tf_cov_parai)\n",
    "    \n",
    "    # Make sure all para %age change is <= 5% for 10 consecutive times...\n",
    "    if np.all(tf_cov_all):\n",
    "        conv_ctr += 1\n",
    "    else:\n",
    "        conv_ctr = 0\n",
    "    \n",
    "    return conv_ctr, conv_ctr > conv_ctr_cap\n",
    "    \n",
    "    \n",
    "def train_model_improved(X, k, convergence_function, initial_values = None):\n",
    "    \"\"\"\n",
    "    Train the mixture model using the \n",
    "    expectation-maximization algorithm. \n",
    "    Which is an interative execution of\n",
    "    the E and M steps from above.\n",
    "    Convergence is reached when convergence_function\n",
    "    returns terminate as True,\n",
    "    see default convergence_function example \n",
    "    in `helper_functions.py`\n",
    "\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    k = int\n",
    "    convergence_function = func\n",
    "    initial_values = None or (MU, SIGMA, PI)\n",
    "\n",
    "    params:\n",
    "    returns:\n",
    "    new_MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    new_SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    new_PI = numpy.ndarray[float] - k x 1\n",
    "    responsibility = numpy.ndarray[numpy.ndarray[float]] - k x m\n",
    "    \"\"\"\n",
    "    # This is single new_convergence_function condition: \n",
    "#     if initial_values is None:\n",
    "#         initial_values = improved_initialization(X, k)\n",
    "    \n",
    "#     MU, SIGMA, PI = initial_values\n",
    "#     para = [MU, SIGMA, PI]\n",
    "#     #loglike  = 0\n",
    "#     conv_ctr = 0\n",
    "#     tf_conv  = False\n",
    "    \n",
    "#     while (tf_conv==False):\n",
    "#         #print('Converge counter: ', conv_ctr)\n",
    "#         #loglike_pre = loglike\n",
    "#         para_pre = para.copy()\n",
    "#         r = E_step(X, MU, SIGMA, PI, k)\n",
    "#         MU, SIGMA, PI = M_step(X, r, k)\n",
    "#         para = [MU, SIGMA, PI]\n",
    "#         #loglike = likelihood(X, PI, MU, SIGMA, k)\n",
    "        \n",
    "#         conv_ctr, tf_conv = new_convergence_function(para_pre, para, conv_ctr)\n",
    "        \n",
    "#     return MU, SIGMA, PI, r    \n",
    "    \n",
    "    \n",
    "    # Following applies both new_convergence_function & default_convergence (both para chg and loglikelihood chg)\n",
    "    if initial_values is None:\n",
    "        initial_values = improved_initialization(X, k)\n",
    "    \n",
    "    MU, SIGMA, PI = initial_values\n",
    "    para = [MU, SIGMA, PI]\n",
    "    loglike  = 0\n",
    "    conv_ctr     = 0\n",
    "    conv_ctr_new = 0\n",
    "    tf_conv     = False\n",
    "    tf_conv_new = False\n",
    "    \n",
    "    while (tf_conv==False) or (tf_conv_new==False):\n",
    "        #print('Converge counter: ', conv_ctr)\n",
    "        loglike_pre = loglike\n",
    "        para_pre = para.copy()\n",
    "        \n",
    "        r = E_step(X, MU, SIGMA, PI, k)\n",
    "        MU, SIGMA, PI = M_step(X, r, k)\n",
    "        \n",
    "        para = [MU, SIGMA, PI]\n",
    "        loglike = likelihood(X, PI, MU, SIGMA, k)\n",
    "        \n",
    "        conv_ctr_new, tf_conv_new = new_convergence_function(para_pre, para, conv_ctr_new)\n",
    "        conv_ctr, tf_conv = default_convergence(loglike_pre, loglike, conv_ctr)\n",
    "        \n",
    "    return MU, SIGMA, PI, r\n",
    "    \n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "# Unittest below will check both of the functions at the same time. \n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_convergence_condition(improved_initialization, train_model_improved, initialize_parameters, train_model, likelihood, new_convergence_function)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Bayesian Information Criterion (20 pts)\n",
    "\n",
    "In our previous solutions, our only criterion for choosing a model was whether it maximizes the posterior likelihood regardless of how many parameters this requires. As a result, the \"best\" model may simply be the model with the most parameters, which would be overfit to the training data.\n",
    "\n",
    "To avoid overfitting, we can use the [Bayesian information criterion](https://en.wikipedia.org/wiki/Bayesian_information_criterion) (a.k.a. BIC) which penalizes models based on the number of parameters they use. In the case of the Gaussian mixture model, this is equal to the number of components times the number of variables per component (mean, variance and mixing coefficient).\n",
    "\n",
    "## Part 4a: Implement BIC\n",
    "\n",
    "5 points\n",
    "\n",
    "Implement `bayes_info_criterion()` to calculate the BIC of a trained Gaussian Mixture Model (based on the given parameters).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "graded"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnitTest passed successfully!\n"
     ]
    }
   ],
   "source": [
    "def bayes_info_criterion(X, PI, MU, SIGMA, k):\n",
    "    \"\"\"\n",
    "    See description above\n",
    "    params:\n",
    "    X = numpy.ndarray[numpy.ndarray[float]] - m x n\n",
    "    MU = numpy.ndarray[numpy.ndarray[float]] - k x n\n",
    "    SIGMA = numpy.ndarray[numpy.ndarray[numpy.ndarray[float]]] - k x n x n\n",
    "    PI = numpy.ndarray[float] - k x 1\n",
    "    k = int\n",
    "    \n",
    "    return:\n",
    "    bayes_info_criterion = int\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate number of para\n",
    "    row, col = X.shape\n",
    "    num_PI = 1\n",
    "    num_SIGMA = col * col\n",
    "    num_MU = col\n",
    "    num_para = k * (num_PI + num_SIGMA + num_MU)\n",
    "    \n",
    "    # Calc loglikelihood\n",
    "    log_like = likelihood(X, PI, MU, SIGMA, k)\n",
    "    BIC = np.log10(row) * num_para - 2 * log_like\n",
    "    \n",
    "    return BIC\n",
    "    \n",
    "    \n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.GMMTests().test_bayes_info(bayes_info_criterion)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4b: Test BIC\n",
    "\n",
    "15 points\n",
    "\n",
    "Now implement `BIC_likelihood_model_test()`, in which you will use the BIC and likelihood to determine the optimal number of components in the `bird_color_24` image. Use the `train_model()` or `train_model_improved()`, iterate from k=2 to k=7 (k - # of clusters) and use the provided means to train a model that minimizes its BIC and a model that maximizes its likelihood.\n",
    "Then, fill out `BIC_likelihood_question()` to return the number of components in both the min-BIC and the max-likelihood model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def BIC_likelihood_model_test():\n",
    "    \"\"\"Test to compare the\n",
    "    models with the lowest BIC\n",
    "    and the highest likelihood.\n",
    "\n",
    "    returns:\n",
    "    n_comp_min_bic = int\n",
    "    n_comp_max_likelihood = int\n",
    "\n",
    "    \"\"\"\n",
    "    comp_means = [\n",
    "        np.array([[0.67644833, 0.63705593, 0.34151605],\n",
    "               [0.82106333, 0.803725  , 0.38302438]]),\n",
    "        np.array([[0.67644833, 0.63705593, 0.34151605],\n",
    "               [0.82106333, 0.803725  , 0.38302438],\n",
    "               [0.48719558, 0.43396747, 0.57330976]]),\n",
    "        np.array([[0.67644833, 0.63705593, 0.34151605],\n",
    "               [0.82106333, 0.803725  , 0.38302438],\n",
    "               [0.48719558, 0.43396747, 0.57330976],\n",
    "               [0.37512508, 0.7997302 , 0.64795305]]),\n",
    "        np.array([[0.67644833, 0.63705593, 0.34151605],\n",
    "               [0.82106333, 0.803725  , 0.38302438],\n",
    "               [0.48719558, 0.43396747, 0.57330976],\n",
    "               [0.37512508, 0.7997302 , 0.64795305],\n",
    "               [0.14751079, 0.351123  , 0.75471674]]),\n",
    "        np.array([[0.67644833, 0.63705593, 0.34151605],\n",
    "               [0.82106333, 0.803725  , 0.38302438],\n",
    "               [0.48719558, 0.43396747, 0.57330976],\n",
    "               [0.37512508, 0.7997302 , 0.64795305],\n",
    "               [0.14751079, 0.351123  , 0.75471674],\n",
    "               [0.56489468, 0.87895182, 0.25817842]]),\n",
    "        np.array([[0.67644833, 0.63705593, 0.34151605],\n",
    "               [0.82106333, 0.803725  , 0.38302438],\n",
    "               [0.48719558, 0.43396747, 0.57330976],\n",
    "               [0.37512508, 0.7997302 , 0.64795305],\n",
    "               [0.14751079, 0.351123  , 0.75471674],\n",
    "               [0.56489468, 0.87895182, 0.25817842],\n",
    "               [0.08769436, 0.80069854, 0.50162118]])\n",
    "        ]\n",
    "    \n",
    "    image_file = 'images/bird_color_24.png'\n",
    "    X = image_to_matrix(image_file).reshape(-1, 3)\n",
    "    row, col = X.shape\n",
    "    \n",
    "    # Initialize for two models\n",
    "    bic_min = np.inf\n",
    "    k_minbic = 0\n",
    "    \n",
    "    loglike_max = -np.inf\n",
    "    k_maxlike = 0\n",
    "    \n",
    "    for Mu in comp_means:\n",
    "        # Calc all para using the given mean\n",
    "        k = Mu.shape[0]\n",
    "        Mu_tmp = np.expand_dims(Mu, axis=1)    # (k*n) --> (k*1*n)\n",
    "        Sigma = (1/row) * np.matmul(np.transpose((np.tile(X, (k,1)).reshape(k, row, col) - Mu_tmp), axes=(0,2,1)), \n",
    "                                    (np.tile(X, (k,1)).reshape(k, row, col) - Mu_tmp))     # (m*n) --> (k*m*n)\n",
    "        Pi = np.repeat(1/k, k)\n",
    "        initial_values = (Mu, Sigma, Pi)\n",
    "        \n",
    "        # Train the model\n",
    "        Mu, Sigma, Pi, r = train_model_improved(X, k, new_convergence_function, initial_values)\n",
    "        \n",
    "        # Calc BIC\n",
    "        bic_tmp = bayes_info_criterion(X, Pi, Mu, Sigma, k)\n",
    "        \n",
    "        # Calc likelihood\n",
    "        loglike_tmp = likelihood(X, Pi, Mu, Sigma, k)\n",
    "        \n",
    "        if bic_tmp < bic_min:\n",
    "            bic_min = bic_tmp\n",
    "            k_minbic = k\n",
    "            \n",
    "        if loglike_tmp > loglike_max:\n",
    "            loglike_max = loglike_tmp\n",
    "            k_maxlike = k\n",
    "    \n",
    "    return k_minbic, k_maxlike\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k_minbic: 7 k_maxlike 7\n"
     ]
    }
   ],
   "source": [
    "# Feel free to use this cell to run your implementation\n",
    "\n",
    "# let's run the BIC test for 5 times\n",
    "# i = 0\n",
    "# while i<=5:\n",
    "#     k_minbic, k_maxlike = BIC_likelihood_model_test()\n",
    "#     print('k_minbic:', k_minbic,'k_maxlike', k_maxlike)\n",
    "#     i+=1\n",
    "\n",
    "k_minbic, k_maxlike = BIC_likelihood_model_test()\n",
    "# print('k_minbic:', k_minbic,'k_maxlike', k_maxlike)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def BIC_likelihood_question():\n",
    "    \"\"\"\n",
    "    Choose the best number of\n",
    "    components for each metric\n",
    "    (min BIC and maximum likelihood).\n",
    "\n",
    "    returns:\n",
    "    pairs = dict\n",
    "    \"\"\"\n",
    "    bic = 7\n",
    "    likelihood = 7\n",
    "    pairs = {\n",
    "        'BIC': bic,\n",
    "        'likelihood': likelihood\n",
    "    }\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Return your name\n",
    "\n",
    "1 point\n",
    "\n",
    "A simple task to wind down the assignment. Return your name from the function aptly called `return_your_name()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def return_your_name():\n",
    "    # return your name\n",
    "    # TODO: finish this\n",
    "    return 'Yuchen An'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Bonus\n",
    "\n",
    "+5 points\n",
    "\n",
    "#### Bonus points are added to the grade for this assignment, not to your overall grade.\n",
    "\n",
    "A crucial part of machine learning is working with very large datasets. As stated before, using for loops over these datasets will result in the code taking many hours, or even several days, to run. Even vectorization can take time if not done properly, and as such there are certain tricks you can perform to get your code to run as fast as physically possible.\n",
    "\n",
    "For this part of the assignment, you will need to implement part of a k-Means algorithm. You are given two arrays - points_array with X n-dimensional points, and means_array with Y n-dimensional points. You will need to return an X x Y array containing the distances from each point in points_array to each point in means_array.\n",
    "\n",
    "Your code will be tested using two very large arrays, against our reference implementation.\n",
    "\n",
    "If your implementation returns the correct answer in time comparable to our implementation, you will receive 5 bonus points on this assignment.\n",
    "\n",
    "For reference, the data used is in the order of thousands of points and hundreds of means, and Bonnie automatically kills a grading script that takes more than 250MB. So please test accordingly locally before submitting, as you may lose a submission for an inefficient solution. It is very likely that you could run out of memory if your implementation is inefficient.\n",
    "\n",
    "\n",
    "You're done with the requirements! Hope you have completed the functions in the `mixture_models.py` file and tested everything using `mixture_tests.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def bonus(points_array, means_array):\n",
    "    \"\"\"\n",
    "    Return the distance from every point in points_array\n",
    "    to every point in means_array.\n",
    "\n",
    "    returns:\n",
    "    dists = numpy array of float\n",
    "    \"\"\"\n",
    "    # TODO: fill in the bonus function\n",
    "    # REMOVE THE LINE BELOW IF ATTEMPTING BONUS\n",
    "    raise NotImplementedError()\n",
    "    return dists\n",
    "\n",
    "# There are no local test for thus question, fill free to create them yourself.\n",
    "# Feel free to play with it in a separate python file, and then just copy over \n",
    "# your implementation before the submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats, you are done with the part of the assignment which is graded\n",
    "### Please follow the instructions in the README to submit your code for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is as promised segmentation of the Point Cloud data. \n",
    "\n",
    "In order to run the code below you first need to install an `open3d` library. If you used `pip install -r requirements.txt` command for this assignment, it should already be installed. Else, you can install it `pip install open3d-python` command, if you used virtual environment, make sure to activate it before running the code.\n",
    "\n",
    "You can also refer to official Open3d documentation http://www.open3d.org/docs/getting_started.html for details about the installation and library itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RGBD (**RGB** + **D**epth) data is usually stored as two separated images, one contains RGB (color) information and second one contains only depth, thus is a grayscale image. Let's load a data sample visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from open3d import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function below load the data\n",
    "def load_rgbd_image(image_path, depth_path):\n",
    "    color_raw = read_image(image_path)\n",
    "    depth_raw = read_image(depth_path)\n",
    "    #  details about function http://www.open3d.org/docs/tutorial/Basic/rgbd_odometry.html\n",
    "    # We are using a data sample from the SUN RGB-D (http://rgbd.cs.princeton.edu/) dataset\n",
    "    return color_raw, depth_raw\n",
    "\n",
    "# We can plot these images separately using the function below\n",
    "def plot_rgbd(color_image, depth_image):\n",
    "    plt.figure(None,(15,15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Color image')\n",
    "    plt.imshow(color_image)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('SUN depth image')\n",
    "    plt.imshow(depth_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "rgbd_dataset = glob.glob('rgbd/image/*.jpg') # TODO fix it\n",
    "image_number = 3 # [0,4] there are five different images in the folder\n",
    "\n",
    "image_file = rgbd_dataset[image_number]\n",
    "depth_file = image_file.replace('image','depth')[:-4] + '.png'\n",
    "assert os.path.isfile(image_file); \n",
    "assert os.path.isfile(depth_file);\n",
    "color_image, depth_image = load_rgbd_image(image_file, depth_file)\n",
    "plot_rgbd(color_image, depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next we can convert the depth image into a point cloud \n",
    "def show_point_cloud(color_raw, depth_raw):\n",
    "    rgbd_image = create_rgbd_image_from_sun_format(color_raw, depth_raw);\n",
    "    pcd = create_point_cloud_from_rgbd_image(rgbd_image, \n",
    "                 PinholeCameraIntrinsic(PinholeCameraIntrinsicParameters.PrimeSenseDefault))\n",
    "    # Flip it, otherwise the pointcloud will be upside down\n",
    "    pcd.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "    draw_geometries([pcd])\n",
    "    return pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pcd = show_point_cloud(color_image, depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets have a look at the structure of the point cloud data\n",
    "pcd_points = np.asarray(pcd.points)\n",
    "print(\"Point cloud data - shape:\", pcd_points.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point cloud data is represented as an unsorted set of the size M x N., where M is the number of points and N is the x,y,z value for each point. If you are interested you can access the color data in `pcd.colors`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to perform a segmentation on the image we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting the number of clusters\n",
    "K = 5\n",
    "# Note: it's just a simple train model run\n",
    "# To improve it you can adapt the best_segment() \n",
    "# to generate the clusters with the best model\n",
    "initial_params = initialize_parameters(pcd_points, K)\n",
    "MU, SIGMA, PI, r = train_model(pcd_points, K,\n",
    "                               convergence_function=default_convergence,\n",
    "                               initial_values=initial_params)\n",
    "clusters = cluster(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a set of size K of distinct color to plot the clusters\n",
    "# Adapted from https://stackoverflow.com/questions/876853/generating-color-ranges-in-python\n",
    "import colorsys\n",
    "HSV_tuples = [(x*1.0/K, 1.0, 1.0) for x in range(K)]\n",
    "color_maps = list(map(lambda x: colorsys.hsv_to_rgb(*x), HSV_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the segmented point cloud data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "or_pcd = PointCloud() # Create new point cloud handler\n",
    "or_pcd.points = Vector3dVector(pcd_points) # set point cloud data\n",
    "colors = np.zeros_like(pcd_points) # initialize colors to 0\n",
    "for i, point in enumerate(np.unique(clusters)):\n",
    "    random_color = color_maps[i]\n",
    "    cluster_mask = (clusters == point) # get the mask of the cluster i\n",
    "    colors[cluster_mask,:] = random_color # set random color to all the point of this segment\n",
    "or_pcd.colors = Vector3dVector(colors) # set color data\n",
    "draw_geometries([or_pcd]) # visualize point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some questions to think about:\n",
    "- Would adding a color help or harm the segmentation results?\n",
    "- How about the case: segment RGB data -> add depth -> convert to Point Cloud -> cluster? Would that help/harm?\n",
    "- Could you think of a way you could compress the point cloud data?\n",
    "\n",
    "Things to try:\n",
    "- Segmentation here is done in purely unsupervised manner, you could manually combine multiple gaussian\n",
    "- How about merging multiple scenes into a single one? You could crop one segment from one scene and place it inside another scene.\n",
    "- Try K-means on point cloud data and see what results does it produces\n",
    "- Can we omit the step of conversion to point cloud? And use depth only? Or depth with x,y coordinates?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~END~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
